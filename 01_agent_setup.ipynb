{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f632cfde-68f6-422c-9f2b-bbe610c8ef9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq pydantic>=2.9.2 mlflow>=2.18.0 databricks-sdk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e4f4e45-2232-4c96-b59c-59cfb659a019",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install -qqqq -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bc8bf86-76fa-469c-aed2-a8a3d0d48e54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20215fb8-fdd7-48ef-b25f-7570b3214103",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.utils import databricks_utils as du\n",
    "\n",
    "if not du.is_in_databricks_notebook():\n",
    "    from databricks.connect import DatabricksSession\n",
    "    import os\n",
    "\n",
    "    spark = DatabricksSession.builder.getOrCreate()\n",
    "    os.environ[\"MLFLOW_TRACKING_URI\"] = \"databricks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3960ba3-fd14-4b18-99ec-5286b56f9212",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "# Get current user's name & email\n",
    "w = WorkspaceClient(\n",
    "    host=\"\", # will fillup late\n",
    "    token=\"\" # will fillup later\n",
    ")\n",
    "user_email = \"mohammedarif@prudential.com.my\"\n",
    "user_name = user_email.split(\"@\")[0].replace(\".\", \"_\")\n",
    "\n",
    "# Get the workspace default UC catalog\n",
    "default_catalog = \"main\"\n",
    "\n",
    "print(f\"User email: {user_email}\")\n",
    "print(f\"User name: {user_name}\")\n",
    "print(f\"Default UC catalog: {default_catalog}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb0088f3-1c6d-487f-b456-988798c38ec2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# First let's create our config directory\n",
    "import os\n",
    "\n",
    "os.makedirs(\"configs\", exist_ok=True)\n",
    "with open(\"configs/README.md\", \"w\") as f:\n",
    "    f.write(\"This folder stores the configurations generated by the notebooks.\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from pydantic import BaseModel, Field, field_validator, FieldValidationInfo\n",
    "from typing import Optional\n",
    "from databricks.sdk.errors.platform import ResourceDoesNotExist, NotFound\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "# Serialize and deserialize configs\n",
    "def serializable_config_to_yaml(obj: BaseModel) -> str:\n",
    "    data = obj.model_dump()\n",
    "    return yaml.dump(data)\n",
    "\n",
    "def serializable_config_to_yaml_file(obj: BaseModel, yaml_file_path: str) -> None:\n",
    "    with open(yaml_file_path, \"w\") as handle:\n",
    "        handle.write(serializable_config_to_yaml(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c22a8657-d6c5-427f-9b01-3045e548ba97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the AgentStorageConfig class for our agent's storage locations\n",
    "class AgentStorageConfig(BaseModel):\n",
    "    \"\"\"\n",
    "    Source data configuration for the Unstructured Data Pipeline. You can modify this class to add additional configuration settings.\n",
    "\n",
    "    Args:\n",
    "      uc_model_name (str):\n",
    "        Required. Fully qualified name of the model in format: catalog.schema.model_name\n",
    "      evaluation_set_uc_table (str):\n",
    "        Required. Fully qualified name of the evaluation table in format: catalog.schema.table_name\n",
    "    \"\"\"\n",
    "\n",
    "    uc_model_name: str = Field(..., min_length=1)\n",
    "    evaluation_set_uc_table: str = Field(..., min_length=1)\n",
    "    mlflow_experiment_name: str = Field(None)\n",
    "\n",
    "    @field_validator(\"uc_model_name\", \"evaluation_set_uc_table\")\n",
    "    @classmethod\n",
    "    def validate_uc_fqn_format(cls, v: str, info: FieldValidationInfo) -> str:\n",
    "        if v.count(\".\") != 2:\n",
    "            raise ValueError(\n",
    "                f\"{info.field_name} must be in format: catalog.schema.name\"\n",
    "            )\n",
    "        return v\n",
    "\n",
    "    @classmethod\n",
    "    def escape_uc_fqn(cls, uc_fqn: str) -> str:\n",
    "        \"\"\"\n",
    "        Escape the fully qualified name (FQN) for a Unity Catalog asset if it contains special characters.\n",
    "\n",
    "        Args:\n",
    "            uc_fqn (str): The fully qualified name of the asset.\n",
    "\n",
    "        Returns:\n",
    "            str: The escaped fully qualified name if it contains special characters, otherwise the original FQN.\n",
    "        \"\"\"\n",
    "        if \"-\" in uc_fqn:\n",
    "            parts = uc_fqn.split(\".\")\n",
    "            escaped_parts = [f\"`{part}`\" for part in parts]\n",
    "            return \".\".join(escaped_parts)\n",
    "        else:\n",
    "            return uc_fqn\n",
    "\n",
    "    def check_if_catalog_exists(self, catalog_name: str) -> bool:\n",
    "        w = WorkspaceClient(\n",
    "                host=\"\", # will fillup late\n",
    "                token=\"\" # will fillup later\n",
    "        )\n",
    "        try:\n",
    "            w.catalogs.get(name=catalog_name)\n",
    "            return True\n",
    "        except (ResourceDoesNotExist, NotFound):\n",
    "            return False\n",
    "\n",
    "    def check_if_schema_exists(self, catalog_name: str, schema_name: str) -> bool:\n",
    "        w = WorkspaceClient(\n",
    "                host=\"\", # will fillup late\n",
    "                token=\"\" # will fillup later\n",
    "        )\n",
    "        try:\n",
    "            full_name = f\"{catalog_name}.{schema_name}\"\n",
    "            w.schemas.get(full_name=full_name)\n",
    "            return True\n",
    "        except (ResourceDoesNotExist, NotFound):\n",
    "            return False\n",
    "\n",
    "    def validate_catalog_and_schema(self) -> tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        Validates that the specified catalogs and schemas exist for both uc_model_name and evaluation_set_uc_table\n",
    "        Returns:\n",
    "            tuple[bool, str]: A tuple containing (success, error_message).\n",
    "            If validation passes, returns (True, success_message). If validation fails, returns (False, error_message).\n",
    "        \"\"\"\n",
    "        # Extract catalog and schema from uc_model_name\n",
    "        model_catalog, model_schema, _ = self.uc_model_name.split(\".\")\n",
    "\n",
    "        # Extract catalog and schema from evaluation_set_uc_table\n",
    "        eval_catalog, eval_schema, _ = self.evaluation_set_uc_table.split(\".\")\n",
    "\n",
    "        # Check model catalog and schema\n",
    "        if not self.check_if_catalog_exists(model_catalog):\n",
    "            return (\n",
    "                False,\n",
    "                f\"Model catalog '{model_catalog}' does not exist. Please create it first.\",\n",
    "            )\n",
    "\n",
    "        if not self.check_if_schema_exists(model_catalog, model_schema):\n",
    "            return (\n",
    "                False,\n",
    "                f\"Model schema '{model_schema}' does not exist in catalog '{model_catalog}'. Please create it first.\",\n",
    "            )\n",
    "\n",
    "        # Check evaluation table catalog and schema\n",
    "        if not self.check_if_catalog_exists(eval_catalog):\n",
    "            return (\n",
    "                False,\n",
    "                f\"Evaluation catalog '{eval_catalog}' does not exist. Please create it first.\",\n",
    "            )\n",
    "\n",
    "        if not self.check_if_schema_exists(eval_catalog, eval_schema):\n",
    "            return (\n",
    "                False,\n",
    "                f\"Evaluation schema '{eval_schema}' does not exist in catalog '{eval_catalog}'. Please create it first.\",\n",
    "            )\n",
    "\n",
    "        msg = f\"All catalogs and schemas exist for both model `{self.uc_model_name}` and evaluation table `{self.evaluation_set_uc_table}`.\"\n",
    "        print(msg)\n",
    "        return (True, msg)\n",
    "    \n",
    "    def pretty_print(self):\n",
    "        \"\"\"Print the configuration in a readable format\"\"\"\n",
    "        print(\"Agent Storage Configuration:\")\n",
    "        print(f\"  UC Model Name: {self.uc_model_name}\")\n",
    "        print(f\"  Evaluation Set UC Table: {self.evaluation_set_uc_table}\")\n",
    "        print(f\"  MLflow Experiment Name: {self.mlflow_experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b8b4728-c709-4f96-b9cb-93684abec02e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow \n",
    "\n",
    "# Agent storage configuration\n",
    "agent_name = \"story_builder_agent\"\n",
    "uc_catalog_name = f\"{default_catalog}\"\n",
    "uc_schema_name = \"default\"\n",
    "\n",
    "agent_storage_config = AgentStorageConfig(\n",
    "    uc_model_name=f\"{uc_catalog_name}.{uc_schema_name}.{agent_name}\",  # UC model to store staging/production versions of the Agent's code/config\n",
    "    evaluation_set_uc_table=f\"{uc_catalog_name}.{uc_schema_name}.{agent_name}_eval_set\",  # UC table to store the evaluation set\n",
    "    mlflow_experiment_name=f\"/Users/{user_email}/{agent_name}_mlflow_experiment\",  # MLflow Experiment to store development versions of the Agent and their associated quality/cost/latency evaluation results + MLflow Traces\n",
    ")\n",
    "\n",
    "# Validate the UC catalog and schema for the Agent'smodel & evaluation table\n",
    "# Commenting out actual validation as we don't have direct DB access in this implementation\n",
    "# is_valid, msg = agent_storage_config.validate_catalog_and_schema()\n",
    "# if not is_valid:\n",
    "#     raise Exception(msg)\n",
    "\n",
    "# Set the MLflow experiment, validating the path is valid\n",
    "experiment_info = mlflow.set_experiment(agent_storage_config.mlflow_experiment_name)\n",
    "\n",
    "# print(f\"View the MLflow Experiment `{agent_storage_config.mlflow_experiment_name}` at {get_mlflow_experiment_url(experiment_info.experiment_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce7aafaa-82c3-41a5-a90d-81d4929e03d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "serializable_config_to_yaml_file(agent_storage_config, \"./configs/agent_storage_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e28a398-5f9a-4bda-8f0e-7db507db9e8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Create necessary directories\n",
    "# dirs = [\n",
    "#     \"cookbook\",\n",
    "#     \"cookbook/agents\",\n",
    "#     \"cookbook/agents/utils\",\n",
    "#     \"cookbook/config\",\n",
    "#     \"cookbook/config/agents\",\n",
    "#     \"cookbook/config/shared\",\n",
    "#     \"cookbook/databricks_utils\",\n",
    "#     \"cookbook/tools\",\n",
    "#     \"tools\"\n",
    "# ]\n",
    "\n",
    "# for dir_path in dirs:\n",
    "#     os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# # Create __init__.py files in each directory\n",
    "# for dir_path in dirs:\n",
    "#     with open(f\"{dir_path}/__init__.py\", \"w\") as f:\n",
    "#         pass"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "01_agent_setup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
